{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import os\n",
    "from alfred_git_data import PRDataset, PR\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "def load_json_from_gzip(gzipped_filepath):\n",
    "    \"\"\"\n",
    "    Loads a JSON file gzipped.\n",
    "\n",
    "    Args:\n",
    "        zip_filepath (str): The path to the gzipped file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The JSON data as a Python dictionary, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with gzip.open(gzipped_filepath, 'r') as z:\n",
    "                data = json.load(z)\n",
    "                return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: GZIP file not found: {gzipped_filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "         print(f\"An unexpected error occurred: {e}\")\n",
    "         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [\"dataset/{dataset_to_load}\"]\n",
    "data_objs = {}\n",
    "for json_file in json_files:\n",
    "    if json_file.endswith(\".gz\"):\n",
    "        data = load_json_from_gzip(json_file)\n",
    "    else:\n",
    "        with open(json_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    if data is not None:\n",
    "        print(f\"Loaded {len(data)} records from {json_file}\")\n",
    "        dst_pr = PRDataset(**data)\n",
    "        data_objs[json_file] = dst_pr\n",
    "    else:\n",
    "        print(f\"Failed to load data from {json_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from alfred_git_data import CommentType\n",
    "def split_comments_by_type(comments):\n",
    "        issue_comments = [comment for comment in comments if comment.type == CommentType.issue]\n",
    "        review_comments = [comment for comment in comments if comment.type == CommentType.review]\n",
    "        file_comments = [comment for comment in comments if comment.type == CommentType.filec]\n",
    "        return issue_comments, review_comments, file_comments\n",
    "\n",
    "def collate_use_case_stats(PR: PR):\n",
    "    \"\"\"\n",
    "    Collates use case statistics from multiple PRDataset objects.\n",
    "\n",
    "    Args:\n",
    "        PR (PR): A PR object.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A Dict containing the aggregated statistics.\n",
    "    \"\"\"\n",
    "    result = {'cross_reference': 0.0,\n",
    "              'network_configuration': 0.0,\n",
    "              'iam_policy': 0.0,\n",
    "              'modification_to_module': 0.0,\n",
    "              'reference_to_variable': 0.0,\n",
    "              'module_usage': 0.0,\n",
    "              'terraform_best_practice': 0.0}\n",
    "    if PR.use_cases is None or not hasattr(PR, 'use_cases'):\n",
    "        # Handle case where use_cases is None\n",
    "        return result\n",
    "    dfu = pd.DataFrame(PR.use_cases)\n",
    "    num_files = len(PR.files)\n",
    "    col_keep = [col for col in dfu.columns.tolist() if not col.endswith(\"file\")]\n",
    "    dfs = dfu[col_keep].sum()/num_files\n",
    "    #dfs[\"#files\"] = num_files\n",
    "    result.update(dfs.to_dict())  # Update the result dictionary with the calculated values\n",
    "    return result\n",
    "\n",
    "def get_stats_df(dst_pr):\n",
    "    # Initialize lists to store metrics\n",
    "    num_files = []\n",
    "    num_comments = []\n",
    "    num_issue_comments = []\n",
    "    num_review_comments = []\n",
    "    num_file_comments = []\n",
    "    num_commits = []\n",
    "    num_pr = []\n",
    "    use_case_stats_list = {}\n",
    "\n",
    "    # Loop over dst_pr to extract metrics\n",
    "    for pr in tqdm(dst_pr.PRs):\n",
    "        num_pr.append(pr.pr_number)\n",
    "        num_files.append(len(pr.files))\n",
    "        num_comments.append(len(pr.comments))\n",
    "        issue_comments, review_comments, file_comments = split_comments_by_type(comments=pr.comments)\n",
    "        num_issue_comments.append(len(issue_comments))\n",
    "        num_review_comments.append(len(review_comments))\n",
    "        num_file_comments.append(len(file_comments))\n",
    "        num_commits.append(len(pr.commits))\n",
    "        use_case_stats = collate_use_case_stats(pr)\n",
    "        for k, v in use_case_stats.items():\n",
    "            # Aggregate use case stats\n",
    "            if k not in use_case_stats_list:\n",
    "                use_case_stats_list[k] = []\n",
    "            use_case_stats_list[k].append(v)\n",
    "\n",
    "\n",
    "\n",
    "    # Create a DataFrame with the metrics\n",
    "    base_info = {\n",
    "         'PR' : num_pr,\n",
    "        '#tf_files': num_files,\n",
    "        '#comments': num_comments,\n",
    "        '#issue_comments': num_issue_comments,\n",
    "        '#review_comments': num_review_comments,\n",
    "        '#file_comments': num_file_comments,\n",
    "        '#commits': num_commits\n",
    "    }\n",
    "    for k, v in use_case_stats_list.items():\n",
    "        # Add each use case stat to the base_info\n",
    "        base_info[k] = v\n",
    "    df = pd.DataFrame(base_info)\n",
    "    return df\n",
    "#df.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = get_stats_df(data_objs[\"dataset/azure_terraform.json\"])\n",
    "#display(HTML(df.head().to_html()))  # Convert the DataFrame to an HTML table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_as_df(dst_pr: PRDataset):\n",
    "    # Initialize lists to store metrics\n",
    "    pr_numbers = []\n",
    "    comment_types = []\n",
    "    comment_bodies = []\n",
    "\n",
    "    # Loop over dst_pr to extract metrics\n",
    "    for pr in tqdm(dst_pr.PRs):\n",
    "        for comment in pr.comments:\n",
    "            pr_numbers.append(pr.pr_number)\n",
    "            comment_types.append(comment.type)\n",
    "            comment_bodies.append(comment.comment)\n",
    "\n",
    "    # Create a DataFrame with the metrics\n",
    "    df = pd.DataFrame({\n",
    "        'PR' : pr_numbers,\n",
    "        'type': comment_types,\n",
    "        'body': comment_bodies\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 713/713 [00:00<00:00, 3324.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PR</th>\n",
       "      <th>#tf_files</th>\n",
       "      <th>#comments</th>\n",
       "      <th>#issue_comments</th>\n",
       "      <th>#review_comments</th>\n",
       "      <th>#file_comments</th>\n",
       "      <th>#commits</th>\n",
       "      <th>cross_reference</th>\n",
       "      <th>network_configuration</th>\n",
       "      <th>iam_policy</th>\n",
       "      <th>modification_to_module</th>\n",
       "      <th>reference_to_variable</th>\n",
       "      <th>module_usage</th>\n",
       "      <th>terraform_best_practice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj_name = {}\n",
    "df = get_stats_df(data_objs[obj_name])\n",
    "display(HTML(df.head().to_html()))  # Convert the DataFrame to an HTML table\n",
    "df.to_excel(\"summary_pr_cisco_eti_path_terraform_infra_repo.xlsx\", index=False)\n",
    "#df_comments = get_comments_as_df(data_objs[obj_name])\n",
    "#display(HTML(df_comments.head(1).to_html()))  # Convert the DataFrame to an HTML table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded JSON data from dataset/rating_new_both(2).json\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file as a dictionary\n",
    "json_file = \"dataset/rating_new_both(2).json\"\n",
    "with open(json_file, 'r') as z:\n",
    "    json_data = json.load(z)\n",
    "# Check if the data was loaded successfully\n",
    "if json_data is not None:\n",
    "    print(f\"Successfully loaded JSON data from {json_file}\")\n",
    "else:\n",
    "    print(f\"Failed to load JSON data from {json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_use_cases_from_PRDataset(dst_or: PRDataset):\n",
    "    \"\"\"\n",
    "    Extracts use cases from a PRDataset object.\n",
    "\n",
    "    Args:\n",
    "        dst_or (PRDataset): The PRDataset object to extract use cases from.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary where keys are PR numbers and values are the corresponding use cases.\n",
    "    \"\"\"\n",
    "    use_cases = {}\n",
    "    for pr in dst_or.PRs:\n",
    "        if pr.use_cases is not None:\n",
    "            use_cases[pr.pr_number] = pr.use_cases\n",
    "    # Flatten the use cases into a list of dictionaries\n",
    "    # This will help in aggregating and analyzing the use cases\n",
    "    # Note: This assumes that each PR's use_cases is a list of dictionaries\n",
    "    # If use_cases is a dictionary, you might want to flatten it differently\n",
    "    return use_cases\n",
    "prs_to_use_cases = get_use_cases_from_PRDataset(data_objs[obj_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 8, 12, 9, 14, 15, 17, 16, 11, 10, 13, 19, 21, 20, 23, 22, 24, 26, 30, 32, 28, 29, 27, 31, 35, 36, 37, 38, 39, 43, 41, 47, 45, 44, 48, 51, 52, 53, 56, 59, 60, 61, 62, 63, 65, 66, 68, 70, 71, 46, 72, 74, 76, 73, 75, 77, 78, 79, 80, 55, 81, 83, 84, 85, 86, 40, 88, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 102, 94, 105, 106, 103, 108, 114, 115, 116, 117, 113, 118, 119, 120, 87, 122, 121, 124, 112, 123, 127, 128, 130, 129, 131, 133, 132, 134, 126, 135, 136, 137, 140, 144, 146, 147, 148, 149, 151, 150, 152, 153, 141, 156, 160, 161, 162, 163, 157, 167, 166, 169, 171, 172, 175, 165, 176, 174, 178, 179, 170, 182, 184, 183, 187, 188, 185, 189, 190, 191, 193, 195, 194, 196, 197, 198, 200, 192, 201, 203, 202, 204, 205, 206, 207, 209, 210, 211, 212, 214, 154, 218, 216, 219, 220, 224, 225, 226, 228, 230, 231, 232, 233, 234, 223, 235, 237, 238, 239, 236, 240, 241, 245, 229, 242, 246, 249, 248, 244, 250, 227, 252, 253, 251, 254, 222, 215, 258, 255, 262, 263, 265, 266, 267, 264, 268, 272, 261, 271, 273, 274, 276, 269, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 289, 247, 291, 288, 292, 294, 296, 299, 300, 303, 304, 305, 297, 306, 307, 308, 309, 310, 311, 312, 313, 314, 259, 315, 316, 317, 295, 320, 321, 322, 318, 323, 326, 319, 329, 328, 324, 332, 330, 333, 334, 337, 338, 339, 340, 341, 342, 344, 327, 345, 347, 346, 349, 335, 351, 348, 350, 353, 354, 356, 357, 358, 359, 363, 365, 287, 290, 366, 368, 362, 361, 364, 369, 371, 372, 373, 374, 375, 370, 378, 379, 367, 377, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 393, 394, 383, 395, 392, 402, 399, 400, 405, 403, 401, 404, 406, 407, 408, 410, 411, 409, 414, 412, 417, 420, 421, 422, 418, 423, 428, 427, 429, 430, 431, 426, 419, 396, 435, 437, 438, 439, 436, 434, 440, 441, 442, 432, 444, 446, 447, 448, 449, 450, 451, 415, 455, 453, 457, 458, 460, 456, 461, 459, 454, 462, 464, 466, 467, 468, 445, 465, 472, 473, 471, 474, 475, 479, 476, 480, 481, 482, 483, 485, 486, 478, 488, 360, 489, 490, 491, 492, 494, 495, 493, 496, 336, 497, 498, 499, 501, 500, 503, 505, 506, 507, 502, 509, 510, 511, 512, 513, 515, 516, 517, 518, 519, 521, 522, 524, 526, 527, 531, 532, 529, 533, 534, 535, 537, 536, 539, 540, 484, 542, 543, 544, 545, 546, 469, 547, 548, 549, 553, 556, 557, 551, 558, 559, 552, 561, 562, 397, 567, 564, 570, 565, 463, 566, 571, 573, 568, 574, 575, 576, 538, 581, 582, 583, 584, 586, 585, 594, 595, 588, 596, 599, 600, 601, 598, 603, 602, 587, 606, 607, 605, 609, 610, 614, 615, 616, 617, 618, 620, 621, 623, 625, 628, 630, 629, 631, 633, 624, 634, 637, 638, 636, 632, 643, 648, 649, 650, 641, 651, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 667, 668, 671, 670, 672, 673, 674, 676, 677, 675, 680, 684, 683, 682, 685, 687, 688, 686, 692, 691, 698, 642, 646, 699, 700, 701, 678, 702, 705, 706, 704, 709, 708, 713, 714, 715, 716, 712, 720, 721, 719, 722, 724, 725, 726, 731, 732, 723, 733, 738, 737, 734, 739, 740, 743, 744, 735, 747, 748, 749, 750, 751, 717, 752, 718, 753, 755, 756, 757, 746, 758, 760, 759, 763, 761, 765, 766, 767, 762, 768, 770, 608, 679, 771, 772, 773, 774, 775, 781, 782, 783, 784, 785, 786, 789, 790, 791, 793, 794, 792, 795, 797, 798, 796, 799, 800, 802, 803, 801, 779, 809, 810, 812, 805, 815, 814, 817, 818, 788, 820, 816, 819, 823, 822, 821, 825, 828, 829, 830, 826, 824, 831, 834, 836, 835, 837, 838, 839, 840, 841, 842, 843, 845, 846, 833, 847, 848, 850, 851, 849, 855, 856, 857, 852, 860, 861, 862, 863, 864, 866, 867, 868, 869])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prs_to_use_cases.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PR number: 190\n",
      "Found PR number: 189\n",
      "Found PR number: 188\n",
      "Found PR number: 187\n",
      "Skipping PR number: 186\n",
      "Found PR number: 185\n",
      "Found PR number: 184\n",
      "Found PR number: 183\n",
      "Found PR number: 182\n",
      "Skipping PR number: 181\n",
      "Skipping PR number: 180\n",
      "Found PR number: 179\n",
      "Found PR number: 178\n",
      "Skipping PR number: 177\n",
      "Found PR number: 176\n",
      "Found PR number: 175\n",
      "Found PR number: 174\n",
      "Skipping PR number: 173\n",
      "Found PR number: 172\n",
      "Found PR number: 171\n",
      "Found PR number: 170\n",
      "Found PR number: 169\n",
      "None\n",
      "Skipping PR number: 168\n",
      "Found PR number: 167\n",
      "Found PR number: 166\n",
      "Found PR number: 165\n",
      "Skipping PR number: 164\n",
      "Found PR number: 163\n",
      "Found PR number: 162\n",
      "Found PR number: 161\n",
      "Found PR number: 160\n",
      "Skipping PR number: 159\n",
      "Skipping PR number: 158\n",
      "Found PR number: 157\n",
      "Found PR number: 156\n",
      "Skipping PR number: 155\n",
      "Found PR number: 154\n",
      "Found PR number: 153\n",
      "Found PR number: 152\n",
      "Found PR number: 151\n",
      "Found PR number: 150\n",
      "Found PR number: 149\n",
      "Found PR number: 148\n",
      "Found PR number: 147\n",
      "Found PR number: 146\n",
      "Skipping PR number: 145\n",
      "Found PR number: 144\n",
      "Skipping PR number: 143\n",
      "Skipping PR number: 142\n",
      "Found PR number: 141\n",
      "Found PR number: 140\n",
      "Skipping PR number: 139\n",
      "Skipping PR number: 138\n",
      "Found PR number: 137\n",
      "Found PR number: 136\n",
      "Found PR number: 135\n",
      "Found PR number: 134\n",
      "Found PR number: 133\n",
      "Found PR number: 132\n",
      "Found PR number: 131\n",
      "Found PR number: 130\n",
      "Found PR number: 129\n",
      "Found PR number: 128\n",
      "Found PR number: 127\n",
      "Found PR number: 126\n",
      "Skipping PR number: 125\n",
      "Found PR number: 124\n",
      "Found PR number: 123\n",
      "Found PR number: 122\n",
      "Found PR number: 121\n",
      "Found PR number: 120\n",
      "Found PR number: 119\n",
      "Found PR number: 118\n",
      "Found PR number: 117\n",
      "Found PR number: 116\n",
      "Found PR number: 115\n",
      "Found PR number: 114\n",
      "Found PR number: 113\n",
      "Found PR number: 112\n",
      "Skipping PR number: 111\n",
      "Skipping PR number: 110\n",
      "Skipping PR number: 109\n",
      "Found PR number: 108\n",
      "Skipping PR number: 107\n",
      "Found PR number: 106\n",
      "Found PR number: 105\n",
      "Skipping PR number: 104\n",
      "Found PR number: 103\n",
      "Found PR number: 102\n",
      "Found PR number: 101\n",
      "Found PR number: 100\n",
      "Found PR number: 99\n",
      "Found PR number: 98\n",
      "Found PR number: 97\n",
      "Found PR number: 96\n",
      "Found PR number: 95\n",
      "Found PR number: 94\n",
      "Skipping PR number: 93\n",
      "Found PR number: 92\n",
      "Found PR number: 91\n",
      "Found PR number: 90\n",
      "Skipping PR number: 89\n",
      "Found PR number: 88\n",
      "Found PR number: 87\n",
      "Found PR number: 86\n",
      "Found PR number: 85\n",
      "Found PR number: 84\n",
      "Found PR number: 83\n",
      "Skipping PR number: 82\n",
      "Found PR number: 81\n",
      "Found PR number: 80\n",
      "Found PR number: 79\n",
      "Found PR number: 78\n",
      "Found PR number: 77\n",
      "Found PR number: 76\n",
      "Found PR number: 75\n",
      "Found PR number: 74\n",
      "Found PR number: 73\n",
      "Found PR number: 72\n",
      "Found PR number: 71\n",
      "Found PR number: 70\n",
      "Skipping PR number: 69\n",
      "Found PR number: 68\n",
      "Skipping PR number: 67\n",
      "Found PR number: 66\n",
      "Found PR number: 65\n",
      "Skipping PR number: 64\n",
      "Found PR number: 63\n",
      "Found PR number: 62\n",
      "Found PR number: 61\n",
      "Found PR number: 60\n",
      "Found PR number: 59\n",
      "Skipping PR number: 58\n",
      "Skipping PR number: 57\n",
      "Found PR number: 56\n",
      "Found PR number: 55\n",
      "Skipping PR number: 54\n",
      "Found PR number: 53\n",
      "Found PR number: 52\n",
      "Found PR number: 51\n",
      "Skipping PR number: 50\n",
      "Skipping PR number: 49\n",
      "Found PR number: 48\n",
      "Found PR number: 47\n",
      "Found PR number: 46\n",
      "Found PR number: 45\n",
      "Found PR number: 44\n",
      "Found PR number: 43\n",
      "Skipping PR number: 42\n",
      "Found PR number: 41\n",
      "Found PR number: 40\n",
      "Found PR number: 39\n",
      "Found PR number: 38\n",
      "Found PR number: 37\n",
      "Found PR number: 36\n",
      "Found PR number: 35\n",
      "Skipping PR number: 34\n",
      "Skipping PR number: 33\n",
      "Found PR number: 32\n",
      "Found PR number: 31\n",
      "Found PR number: 30\n",
      "Found PR number: 29\n",
      "Found PR number: 28\n",
      "Found PR number: 27\n",
      "Found PR number: 26\n",
      "Skipping PR number: 25\n",
      "Found PR number: 24\n",
      "Found PR number: 23\n",
      "Found PR number: 22\n",
      "Found PR number: 21\n",
      "Found PR number: 20\n",
      "Found PR number: 19\n",
      "aws_dragonfly-prod_eu-central-1_eks_dragonfly-prod-euc1-1_main.tf matched with local file in use case for PR 19\n",
      "aws_dragonfly-prod_eu-central-1_eks_dragonfly-prod-euc1-1_main.tf matched with local file in use case for PR 19\n",
      "aws_dragonfly-prod_eu-central-1_eks_dragonfly-prod-euc1-1_main.tf matched with local file in use case for PR 19\n",
      "aws_dragonfly-prod_eu-central-1_eks_dragonfly-prod-euc1-1_main.tf matched with local file in use case for PR 19\n",
      "Skipping PR number: 18\n",
      "Found PR number: 17\n",
      "Found PR number: 16\n",
      "aws_eticloud-preproduction_us-east-2_eks_damarcil-test-use2-1_main.tf matched with local file in use case for PR 16\n",
      "Found PR number: 15\n",
      "Found PR number: 14\n",
      "Found PR number: 13\n",
      "Found PR number: 12\n",
      "Found PR number: 11\n",
      "Found PR number: 10\n",
      "Found PR number: 9\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 9\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 9\n",
      "Found PR number: 8\n",
      "Skipping PR number: 7\n",
      "Found PR number: 6\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-cookiesncream-1_main.tf matched with local file in use case for PR 6\n",
      "Found PR number: 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-allinone-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-allinone-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-allinone-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-allinone-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-allinone-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-allinone-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-cookiesncream-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-cookiesncream-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-cookiesncream-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-cookiesncream-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-cookiesncream-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-cookiesncream-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-icecream-1_eso.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-icecream-1_eso.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-icecream-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-icecream-1_main.tf matched with local file in use case for PR 5\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-icecream-1_main.tf matched with local file in use case for PR 5\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_eso.tf matched with local file in use case for PR 5\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 5\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 5\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 5\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 5\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 5\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_argocd.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_data.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_eks-otel-irsa.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_locals.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_provider.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_provider.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_variables.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_variables.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_versions.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_versions.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_vpc.tf matched with local file in use case for PR 5\n",
      "modules_eks_all_in_one_vpc.tf matched with local file in use case for PR 5\n",
      "Found PR number: 4\n",
      "aws_eticloud-scratch-c_us-east-2_eks_eks-allinone-1_main.tf matched with local file in use case for PR 4\n",
      "modules_eks_all_in_one_variables.tf matched with local file in use case for PR 4\n",
      "modules_eks_all_in_one_variables.tf matched with local file in use case for PR 4\n",
      "Found PR number: 3\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 3\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 3\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 3\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 3\n",
      "aws_rosey-test_eu-west-1_eks_rosey-dev-euw1-1_main.tf matched with local file in use case for PR 3\n",
      "modules_eks_all_in_one_eks-otel-irsa.tf matched with local file in use case for PR 3\n",
      "modules_eks_all_in_one_provider.tf matched with local file in use case for PR 3\n",
      "modules_eks_all_in_one_variables.tf matched with local file in use case for PR 3\n",
      "modules_eks_all_in_one_variables.tf matched with local file in use case for PR 3\n",
      "modules_eks_composition_vpc-endpoints_main.tf matched with local file in use case for PR 3\n",
      "modules_eks_composition_vpc-endpoints_main.tf matched with local file in use case for PR 3\n",
      "Found PR number: 2\n",
      "modules_eks_all_in_one_variables.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_variables.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-instance.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-instance.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-instance.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-instance.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-instance.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-instance.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-instance.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-instance.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-keypair.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-keypair.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-keypair.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-sg.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-sg.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_vpc-bastion-sg.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_eks-alb-irsa.tf matched with local file in use case for PR 2\n",
      "modules_eks_all_in_one_eks-otel-irsa.tf matched with local file in use case for PR 2\n",
      "Found PR number: 1\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "df2 = df.set_index(\"PR\")\n",
    "rest_list = []\n",
    "counter = 0\n",
    "\n",
    "base_cases = {'cross_reference': None,\n",
    "               'network_configuration': None,\n",
    "               'iam_policy': None,\n",
    "               'modification_to_module': None,\n",
    "               'reference_to_variable': None,\n",
    "               'module_usage': None,\n",
    "               'terraform_best_practice': None}\n",
    "for key,val in json_data.items():\n",
    "    pr_num = int(key.split(\"pr_number_\")[-1])\n",
    "    if pr_num in prs_to_use_cases:\n",
    "        print(\"Found PR number:\", pr_num)\n",
    "        # The PR number exists in the use cases\n",
    "        # You can now process this entry further if needed\n",
    "        local_use_case = prs_to_use_cases[pr_num]\n",
    "    else:\n",
    "        print(\"Skipping PR number:\", pr_num)\n",
    "        continue\n",
    "    for key2 , val2 in val.items():\n",
    "        if \".tf\" in key2:\n",
    "            for rating_obj in val2:\n",
    "                if rating_obj is not None and rating_obj.get(\"comment\") is not None:\n",
    "                    # Extract the body of the comment\n",
    "                    body = rating_obj[\"comment\"]\n",
    "                    rating = rating_obj.get(\"rating\", None)\n",
    "                    for cmt in local_use_case:\n",
    "                        if cmt[\"local_file\"] == key2:\n",
    "                            rest = deepcopy(base_cases)\n",
    "                            print(key2, \"matched with local file in use case for PR\", pr_num)\n",
    "                            for c in rest.keys():\n",
    "                                try:\n",
    "                                    if cmt[c] > 0:\n",
    "                                        rest[c] = rating\n",
    "                                except Exception as e:\n",
    "                                    print(f\"ERROR {c} {cmt}\")\n",
    "                            rest[\"PR\"] = pr_num\n",
    "                            rest[\"local_file\"] = key2\n",
    "                            rest_list.append(rest)  # Append the updated dictionary to the list                              \n",
    "                else:\n",
    "                    print(rating_obj)\n",
    "            # Handle file-specific keys\n",
    "            #print(key2)\n",
    "            #print(val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_by_case = pd.DataFrame(rest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating_by_case['local_file'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_by_case.to_excel(\"review_cisco_eti_path_terraform_infra_repo_with_ratings.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cross_reference': 1,\n",
       "  'network_configuration': 1,\n",
       "  'iam_policy': 1,\n",
       "  'modification_to_module': 0,\n",
       "  'reference_to_variable': 0,\n",
       "  'module_usage': 0,\n",
       "  'terraform_best_practice': 1,\n",
       "  'local_file': 'aws_eticloud-preproduction_us-east-2_eks_eks-dev-3_main.tf',\n",
       "  'original_file': 'aws/eticloud-preproduction/us-east-2/eks/eks-dev-3/main.tf'},\n",
       " {'cross_reference': 1,\n",
       "  'network_configuration': 0,\n",
       "  'iam_policy': 0,\n",
       "  'modification_to_module': 0,\n",
       "  'reference_to_variable': 0,\n",
       "  'module_usage': 0,\n",
       "  'terraform_best_practice': 0,\n",
       "  'local_file': 'aws_eticloud-preproduction_us-east-2_eks_eks-dev-3_provider.tf',\n",
       "  'original_file': 'aws/eticloud-preproduction/us-east-2/eks/eks-dev-3/provider.tf'}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prs_to_use_cases[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2744184134', '2744190602', '2744190648', 'aws_eticloud-scratch-c_eks_eks-butterscotch-1_main.tf', 'modules_eks_bastion.tf', 'modules_eks_keypair.tf', 'modules_eks_variables.tf', 'modules_eks_vpc-prefixlist.tf', 'modules_eks_vpc.tf', '2706949773', '2744191079', '2744197911', '2706957431', '2744198421', '2744204988', '2706968663', '2744205722', '2744212409', '2744212463', '2744213183', '2744218050', '2706983464', '2744218578', '2744224689', '2744224740', '2744225158', '2744233171', '2707010752', '2744233728', '2744241315', 'aws_eticloud-scratch-c_us-east-2_eks_eks-butterscotch-1_provider.tf', '2707019923', '2744241632', '2744246388', '2744246425', '2744246827', '2744252204', '2744252278', '2744253001', '2749036752', '2749037618', '2749045377', 'aws_eticloud-scratch-c_us-east-2_eks_eks-butterscotch-1_backend.tf', 'aws_eticloud-scratch-c_us-east-2_eks_eks-butterscotch-1_locals.tf', 'modules_eks_vpc-bastion-keypair.tf', 'modules_eks_vpc-bastion.tf', '2711336293', '2749053400', '2749063954', '2711353904', 'aws_eticloud-scratch-c_us-east-2_eks_eks-butterscotch-1_main.tf', '2749077702', '2749085532', '2711374358', '2749101369', '2749112120', '2711400778', '2749112666', '2749122194', 'modules_eks_eks-iam.tf', 'modules_eks_eks-kube-auth-cm.tf', 'modules_eks_eks-launchtemplate.tf', '2711411522', 'modules_eks_eks-nodegroup.tf', 'modules_eks_eks.tf', '2749122773', '2749134105', 'aws_eticloud-scratch-c_us-east-2_eks_eks-blackforest-1_main.tf', '2711421796', '2749134784', '2749176180', '2749212937', '2749225018', '2711518072', '2749231806', '2749242182', '2749242259', '2749243157', '2749314106', '2749324273', 'aws_eticloud-scratch-c_us-east-2_eks_eks-derbypie-1_main.tf', 'aws_eticloud-scratch-c_us-east-2_eks_eks-derbypie-1_variables.tf', '2711613040', '2749340561', '2749342376', '2749369543', '2749414138', '2749415109', '2749432482', '2749450330'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df2.loc[int(pr_num), :]\n",
    "val.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.03,\n",
    "    specs=[[{\"type\": \"table\"}],\n",
    "           [{\"type\": \"table\"}],\n",
    "           #[{\"type\": \"scatter\"}]\n",
    "           ]\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=['PR', '#tf_files', '#comments', '#issue_comments', '#review_comments',\n",
    "       '#file_comments', '#commits'],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[df[k].tolist() for k in df.columns],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=['PR', 'type', 'body'],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[df_comments[k].tolist() for k in df.columns],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(df_comments.columns)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu = pd.DataFrame(dst_pr.PRs[0].use_cases)\n",
    "num_files = len(dst_pr.PRs[0].files)\n",
    "col_keep = [col for col in dfu.columns.tolist() if not col.endswith(\"file\")]\n",
    "dfs = dfu[col_keep].sum()/num_files\n",
    "dfs[\"#files\"] = num_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cross_reference': 0.890625,\n",
       " 'network_configuration': 0.265625,\n",
       " 'iam_policy': 0.3125,\n",
       " 'modification_to_module': 0.078125,\n",
       " 'reference_to_variable': 0.625,\n",
       " 'module_usage': 0.125,\n",
       " 'terraform_best_practice': 0.828125,\n",
       " '#files': 64.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
